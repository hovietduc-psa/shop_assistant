# Application Settings
DEBUG=false
TESTING=false
SECRET_KEY=your-secret-key-change-in-production
LOG_LEVEL=INFO

# Database Configuration
DATABASE_URL=postgresql://postgres:password@localhost:5432/shop_assistant

# Redis Configuration
REDIS_URL=redis://localhost:6379/0

# OpenRouter Configuration
OPENROUTER_API_KEY=your-openrouter-api-key
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
DEFAULT_LLM_MODEL=openai/gpt-4

# ===========================================
# 3-STAGE MODEL CONFIGURATION
# ===========================================
# Each stage can use a different model for optimal cost and performance

# STAGE 1: Intent Classification (High Accuracy, Fast Response)
# Recommended: meta-llama/llama-3.1-8b-instruct, google/gemini-flash-1.5, openai/gpt-3.5-turbo
INTENT_CLASSIFICATION_MODEL=meta-llama/llama-3.1-8b-instruct

# STAGE 2: Tool Call/Execution (Balanced Performance)
# Recommended: openai/gpt-4o-mini, meta-llama/llama-3.1-8b-instruct, openai/gpt-3.5-turbo
TOOL_CALL_MODEL=openai/gpt-4o-mini

# STAGE 3: Response Generation (Creative Quality)
# Recommended: openai/gpt-4o-mini, meta-llama/llama-3.1-8b-instruct, openai/gpt-3.5-turbo
RESPONSE_GENERATION_MODEL=openai/gpt-4o-mini

# ===========================================
# COST-OPTIMIZATION EXAMPLES
# ===========================================
# Uncomment and customize these examples to optimize costs:

# Example 1: Maximum Cost Savings (~25% cheaper than default)
# INTENT_CLASSIFICATION_MODEL=google/gemini-flash-1.5
# TOOL_CALL_MODEL=meta-llama/llama-3.1-8b-instruct
# RESPONSE_GENERATION_MODEL=meta-llama/llama-3.1-8b-instruct

# Example 2: Best Performance (Fast responses)
# INTENT_CLASSIFICATION_MODEL=meta-llama/llama-3.1-8b-instruct
# TOOL_CALL_MODEL=openai/gpt-3.5-turbo
# RESPONSE_GENERATION_MODEL=openai/gpt-4o-mini

# Example 3: Balanced Quality and Cost
# INTENT_CLASSIFICATION_MODEL=google/gemini-flash-1.5
# TOOL_CALL_MODEL=openai/gpt-4o-mini
# RESPONSE_GENERATION_MODEL=openai/gpt-4o-mini

# Example 4: All Llama 3.1 8B (Most cost-effective)
# INTENT_CLASSIFICATION_MODEL=meta-llama/llama-3.1-8b-instruct
# TOOL_CALL_MODEL=meta-llama/llama-3.1-8b-instruct
# RESPONSE_GENERATION_MODEL=meta-llama/llama-3.1-8b-instruct

# Cohere Configuration
COHERE_API_KEY=your-cohere-api-key
DEFAULT_EMBEDDING_MODEL=embed-english-v3.0

# Security Settings
ACCESS_TOKEN_EXPIRE_MINUTES=30
REFRESH_TOKEN_EXPIRE_DAYS=7

# Rate Limiting
RATE_LIMIT_PER_MINUTE=60
RATE_LIMIT_BURST=10

# CORS Settings
ALLOWED_HOSTS=http://localhost:3000,http://localhost:8000

# Session Settings
SESSION_TIMEOUT_MINUTES=30
MAX_CONVERSATION_LENGTH=50

# File Upload Settings
MAX_UPLOAD_SIZE=10485760  # 10MB in bytes

# Pagination
DEFAULT_PAGE_SIZE=20
MAX_PAGE_SIZE=100

# Shopify Configuration
SHOPIFY_SHOP_DOMAIN=your-shop-domain.myshopify.com
SHOPIFY_ACCESS_TOKEN=your-shopify-access-token
SHOPIFY_API_VERSION=2025-10
SHOPIFY_WEBHOOK_SECRET=your-shopify-webhook-secret
SHOPIFY_APP_SECRET=your-shopify-app-secret

# Shopify API Limits
SHOPIFY_RATE_LIMIT_PER_SECOND=2
SHOPIFY_BURST_LIMIT=40
SHOPIFY_BATCH_SIZE=250